{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "# may need to add the nltk library\n",
    "# !pip install nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have issues reading in the stopwords, you may need to run the\n",
    "# following two lines of code\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we get going, be sure to download the data (i.e. the corpus)\n",
    "#\n",
    "# this file get unzipped and put into a subfolder within this directory called easy_ham\n",
    "# https://spamassassin.apache.org/old/publiccorpus/20030228_easy_ham.tar.bz2\n",
    "#\n",
    "# this file get unzipped and put into a subfolder within this directory called spam\n",
    "# https://spamassassin.apache.org/old/publiccorpus/20030228_spam.tar.bz2\n",
    "#\n",
    "# defining some global variables\n",
    "STOPS = stopwords.words(\"english\")\n",
    "EXCLUDE = set(string.punctuation) | set([\"''\", \"BR\", \"--\", \"/td\", \"nbsp\", \"2002\", \"localhost\", \"&nbsp\"])\n",
    "SPAMPATH = \"./spam/\"\n",
    "HAMPATH = \"./easy_ham/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these stopwords are added because of the nature of the corpus\n",
    "# basically, the email text includes word or tags that are part of the\n",
    "# email headder so we don't want to use them when analyzing the\n",
    "# text of the emails\n",
    "STOPS.extend(['delivery-date', 'jalapeno', 'return-path', 'delivered-to', 'received', 'esmtp', 'smtp'])\n",
    "STOPS.extend(['message-id', 'imap', 'date', 'subject', 'list-help', 'list-post', 'list-subscribe', 'list-archive'])\n",
    "STOPS.extend(['x-beenthere', 'mime-version', 'errors-to', 'list-unsubscribe', 'x-mailman-version'])\n",
    "STOPS.extend(['content-type', 'list-id', 'dogmaslashnullorg', 'xentcom', 'in-reply-to'])\n",
    "STOPS.extend(['jmasonorg', 'sender', 'bulk', 'content-transfer-encoding'])\n",
    "STOPS.extend(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\n",
    "STOPS.extend(['sun', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a list of words and makes them a string\n",
    "def ListToString(inputlist):\n",
    "    cleanstring = \"\"\n",
    "    for each in inputlist:\n",
    "        cleanstring = cleanstring + each + \" \"\n",
    "    return cleanstring.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterWord(s):\n",
    "    \"\"\"\n",
    "    Receives a string and determines whether or not it is a string that should be used\n",
    "    for analysis (keep = 1) and passes back a clean version of the string.\n",
    "    \"\"\"\n",
    "    keep = 1 #default is to keep the word\n",
    "    cleanstring = s.lower()\n",
    "    drop_chars = \",.:;!\"\n",
    "    for c in drop_chars:\n",
    "        cleanstring = cleanstring.replace(c, \"\")\n",
    "    bad_chars = \"><#$/=0123456789+()&*@?\"\n",
    "    for c in bad_chars:\n",
    "        if cleanstring.find(c)!=-1:\n",
    "            keep=0\n",
    "    if len(cleanstring)<3:\n",
    "        keep=0\n",
    "    if cleanstring in STOPS:\n",
    "        keep =0\n",
    "    if cleanstring in EXCLUDE:\n",
    "        keep=0\n",
    "    return keep, cleanstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanWords(wordlist):\n",
    "    \"\"\"\n",
    "    Process go go through a list of words and clean each of them up.  Passes back\n",
    "    a list of clean words.\n",
    "    \"\"\"\n",
    "    filtered_words =[]\n",
    "    for each in wordlist:\n",
    "        flag, cleanstring = FilterWord(each)\n",
    "        if flag==1:\n",
    "            filtered_words.append(cleanstring)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main part of the code\n",
    "# it will go through all of the documents\n",
    "# found within each of the folders and add each file to the dataframe\n",
    "#\n",
    "# the dataframe has the following variables:\n",
    "# id:  this is just a number that gets incremented for each record\n",
    "# spam:  binary variable; coded as 1 when the email is spam\n",
    "# file:  the name of the file\n",
    "# words:  a string that contains all of the filtered words in the email\n",
    "#\n",
    "df = pd.DataFrame(columns=['id', 'spam', 'file', 'words'])\n",
    "count = 0\n",
    "for (dirpath, dirnames, filenames) in os.walk(SPAMPATH):\n",
    "    for file in filenames:\n",
    "        infile=(SPAMPATH + file)\n",
    "        f = open(infile, 'r', encoding=\"Latin-1\")\n",
    "        s = f.read()\n",
    "        f.close()\n",
    "        words = s.split()\n",
    "        words = CleanWords(words)\n",
    "        cleanstring = ListToString(words)\n",
    "        df = df.append({'id':count, 'spam':1, 'file':file, 'words':cleanstring}, ignore_index=True)\n",
    "        count = count+1\n",
    "for (dirpath, dirnames, filenames) in os.walk(HAMPATH):\n",
    "    for file in filenames:\n",
    "        infile=(HAMPATH + file)\n",
    "        f = open(infile, 'r', encoding=\"Latin-1\")\n",
    "        s = f.read()\n",
    "        f.close()\n",
    "        words = s.split()\n",
    "        words = CleanWords(words)\n",
    "        cleanstring = ListToString(words)\n",
    "        df = df.append({'id':count, 'spam':0, 'file':file, 'words':cleanstring}, ignore_index=True)\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we have the dataframe all set for the next step, we\n",
    "# save the dataframe to a csv file\n",
    "df.to_csv('email_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
