{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPS = stopwords.words(\"english\")\n",
    "EXCLUDE = set(string.punctuation) | set([\"''\", \"BR\", \"--\", \"/td\", \"nbsp\", \"2002\", \"localhost\", \"&nbsp\"])\n",
    "SPAMPATH = \"./spam/\"\n",
    "HAMPATH = \"./easy_ham/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPS.extend(['delivery-date', 'jalapeno', 'return-path', 'delivered-to', 'received', 'esmtp', 'smtp'])\n",
    "STOPS.extend(['message-id', 'imap', 'date', 'subject', 'list-help', 'list-post', 'list-subscribe', 'list-archive'])\n",
    "STOPS.extend(['x-beenthere', 'mime-version', 'errors-to', 'list-unsubscribe', 'x-mailman-version'])\n",
    "STOPS.extend(['content-type', 'list-id', 'dogmaslashnullorg', 'xentcom', 'in-reply-to'])\n",
    "STOPS.extend(['jmasonorg', 'sender', 'bulk', 'content-transfer-encoding'])\n",
    "STOPS.extend(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'])\n",
    "STOPS.extend(['sun', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ListToString(inputlist):\n",
    "    cleanstring = \"\"\n",
    "    for each in inputlist:\n",
    "        cleanstring = cleanstring + each + \" \"\n",
    "    return cleanstring.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterWord(s):\n",
    "    \"\"\"\n",
    "    Receives a string and determines whether or not it is a string that should be used\n",
    "    for analysis (keep = 1) and passes back a clean version of the string.\n",
    "    \"\"\"\n",
    "    keep = 1 #default is to keep the word\n",
    "    cleanstring = s.lower()\n",
    "    drop_chars = \",.:;!\"\n",
    "    for c in drop_chars:\n",
    "        cleanstring = cleanstring.replace(c, \"\")\n",
    "    bad_chars = \"><#$/=0123456789+()&*@?\"\n",
    "    for c in bad_chars:\n",
    "        if cleanstring.find(c)!=-1:\n",
    "            keep=0\n",
    "    if len(cleanstring)<3:\n",
    "        keep=0\n",
    "    if cleanstring in STOPS:\n",
    "        keep =0\n",
    "    if cleanstring in EXCLUDE:\n",
    "        keep=0\n",
    "    return keep, cleanstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanWords(wordlist):\n",
    "    \"\"\"\n",
    "    Process go go through a list of words and clean each of them up.  Passes back\n",
    "    a list of clean words.\n",
    "    \"\"\"\n",
    "    filtered_words =[]\n",
    "    for each in wordlist:\n",
    "        flag, cleanstring = FilterWord(each)\n",
    "        if flag==1:\n",
    "            filtered_words.append(cleanstring)\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id', 'spam', 'file', 'words'])\n",
    "count = 0\n",
    "for (dirpath, dirnames, filenames) in os.walk(SPAMPATH):\n",
    "    for file in filenames:\n",
    "        infile=(SPAMPATH + file)\n",
    "        f = open(infile, 'r', encoding=\"Latin-1\")\n",
    "        s = f.read()\n",
    "        f.close()\n",
    "        #s = ''.join(filter(lambda x: x in string.printable, s))\n",
    "        #wordlist=s.split()\n",
    "        words = s.split()\n",
    "        words = CleanWords(words)\n",
    "        cleanstring = ListToString(words)\n",
    "        # print(len(words))\n",
    "        # print(words)\n",
    "        df = df.append({'id':count, 'spam':1, 'file':file, 'words':cleanstring}, ignore_index=True)\n",
    "        count = count+1\n",
    "for (dirpath, dirnames, filenames) in os.walk(HAMPATH):\n",
    "    for file in filenames:\n",
    "        infile=(HAMPATH + file)\n",
    "        f = open(infile, 'r', encoding=\"Latin-1\")\n",
    "        s = f.read()\n",
    "        f.close()\n",
    "        #s = ''.join(filter(lambda x: x in string.printable, s))\n",
    "        #wordlist=s.split()\n",
    "        words = s.split()\n",
    "        words = CleanWords(words)\n",
    "        cleanstring = ListToString(words)\n",
    "        # print(len(words))\n",
    "        # print(words)\n",
    "        df = df.append({'id':count, 'spam':0, 'file':file, 'words':cleanstring}, ignore_index=True)\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('email_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
