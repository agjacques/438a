{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corpus and drop the missing rows\n",
    "df = pd.read_csv(\"./email_corpus.csv\")\n",
    "df = df.dropna()\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sample into 80% for training and 20% for testing\n",
    "df['mask'] = [np.random.uniform(0,1)  for k in df.index]\n",
    "train = df[df['mask'] < 0.8]\n",
    "test = df[df['mask']>= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two lists of words that bring together all of the words found\n",
    "# in the spam and ham training rows\n",
    "spamwords = []\n",
    "spamcount = 0\n",
    "hamwords = []\n",
    "hamcount = 0\n",
    "for index, row in train.iterrows():\n",
    "    li = list(row['words'].split(' '))\n",
    "    if row['spam']==1:\n",
    "        spamcount = spamcount + 1\n",
    "        spamwords = spamwords + li\n",
    "    else:\n",
    "        hamcount = hamcount + 1\n",
    "        hamwords = hamwords + li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in all of the ham emails:  27921\n"
     ]
    }
   ],
   "source": [
    "# getting all of the words found in the ham emails\n",
    "hamdist = nltk.FreqDist(hamwords)\n",
    "hamset = []\n",
    "for each in hamdist:\n",
    "    hamset.append(each)\n",
    "print(\"The number of words in all of the ham emails: \", len(hamset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in all of the spam emails:  10852\n"
     ]
    }
   ],
   "source": [
    "# getting all of the words found in the spam emails\n",
    "spamdist = nltk.FreqDist(spamwords)\n",
    "spamset = []\n",
    "for each in spamdist:\n",
    "    spamset.append(each)\n",
    "print(\"The number of words in all of the spam emails: \",len(spamset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a Venn Diagram perspective, we create two functions to help us\n",
    "# understand the set of words\n",
    "\n",
    "#this function returns all of the words shared between two sets\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "# this function returns all of the words found only in the first set\n",
    "def difference (lst1, lst2):\n",
    "    result = []\n",
    "    for element in lst1:\n",
    "        if element not in lst2:\n",
    "            result.append(element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words shared by ham and spam:  5761\n",
      "The number of words only in spam:  5091\n",
      "The number of words only in ham:  22160\n"
     ]
    }
   ],
   "source": [
    "# we now look at taking the two sets and making three sets\n",
    "# intersection_set:  words found in both ham and spam\n",
    "# spamonly_set:  words found in spam but not ham\n",
    "# hamonly_set:  words found in ham but not spam\n",
    "    \n",
    "intersection_set = intersection(hamset, spamset)\n",
    "print(\"The number of words shared by ham and spam: \",len(intersection_set))\n",
    "\n",
    "spamonly_set = difference (spamset, hamset)\n",
    "print(\"The number of words only in spam: \", len(spamonly_set))\n",
    "\n",
    "hamonly_set = difference (hamset, spamset)\n",
    "print(\"The number of words only in ham: \", len(hamonly_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's go through the full dataframe now and get a count of ham, spam,\n",
    "# and shared words\n",
    "\n",
    "# create a column in the dataframe for spamcount\n",
    "df['spamcount']=0\n",
    "df['hamcount']=0\n",
    "df['sharedcount']=0\n",
    "\n",
    "for ind in df.index:\n",
    "    li = list(df.loc[ind, 'words'].split(' '))\n",
    "    df.loc[ind, 'spamcount'] = len(intersection(li, spamonly_set))\n",
    "    df.loc[ind, 'hamcount'] = len(intersection(li, hamonly_set))\n",
    "    df.loc[ind, 'sharedcount'] = len(intersection(li, intersection_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[495   2]\n",
      " [  7 101]]\n"
     ]
    }
   ],
   "source": [
    "# one approach we can take is to look at hamcount and spamcount\n",
    "# and just see which one is larger.  If spamcount>=hamcount,\n",
    "# then it seem logical that it is a spam email.  However,\n",
    "# when spamcount<hamcount, then it probably is ham.  Let's\n",
    "# try this on our testing data set.\n",
    "\n",
    "df['simple_prediction']=0 #default is that email is ham unless the condition is met\n",
    "df.loc[df['spamcount']>=df['hamcount'], 'simple_prediction']= 1\n",
    "\n",
    "df['result']='unknown'\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==1), 'result']= \"true positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==1), 'result']= \"false negative\"\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==0), 'result']= \"false positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==0), 'result']= \"true negative\"\n",
    "\n",
    "train = df[df['mask'] < 0.8]\n",
    "test = df[df['mask']>= 0.8]\n",
    "results = confusion_matrix(test['spam'], test['simple_prediction'])\n",
    "print ('Confusion Matrix :')\n",
    "print(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  2 :  ['zzzzasonorg', 'hallo']\n",
      "HAM  3 :  ['english', 'bother', 'russian']\n",
      "\n",
      "\n",
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  2 :  ['zzzzasonorg', 'adv']\n",
      "HAM  4 :  ['enterprises', 'ass', 'x-accept-language', 'beach']\n",
      "\n",
      "\n",
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  9 :  ['purchasing', 'traditionally', 'mlm', \"'remove'\", 'multi-level', 'intrusion', 'zzzzasonorg', 'risk-free', 'miracle']\n",
      "HAM  24 :  ['leg', 'carbon', '\"look', 'exception', 'ingenious', 'scream', 'winner', 'smiling', 'flaws', 'cautious', 'hoopla', 'likes', 'bones', 'overly', 'deep', 'definitely', 'awhile', 'positions', 'initially', 'arm', 'convinced', 'excited', 'magic', 'dubious']\n",
      "\n",
      "\n",
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  4 :  ['attained', 'zzzzasonorg', 'cocks', 'overlook']\n",
      "HAM  6 :  ['sucking', 'scared', 'gauge', 'showed', 'hall', 'tons']\n",
      "\n",
      "\n",
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  14 :  ['helvetica', 'llc\"', 'sans-serif', 'warehouse', 'padding-right', 'arial', 'padding-left', 'none\"', 'lbs', 'font-size', 'aluminum', 'liabilities', 'zzzzasonorg', 'background-color']\n",
      "HAM  45 :  ['smallest', 'emit', 'martin', 'cat', 'prove', 'distributor', 'porous', 'inset', 'cushions', 'lecture', 'particularly', 'melt', 'barrier', 'cups', 'william', 'rubber', 'seat', 'covered', 'chapter', 'electricity', 'spray', 'otto', 'quietly', 'obsolete', 'ignoring', 'perform', 'pda', 'blaming', 'gas', 'measuring', 'definitely', 'resin', '\"industry', 'bogus', 'welcomes', 'blends', 'australian', 'contribute', 'standardized', 'convection', 'tank', 'stupid', 'garbage', 'spaces', 'self-contained']\n",
      "\n",
      "\n",
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  13 :  ['furnish', 'seizure', 'indulgence', 'utmost', 'screening', 'intl', 'modalities', 'crave', 'bodyguards', 'nos', 'zzzzasonorg', 'implore', 'kabila']\n",
      "HAM  20 :  ['modesty', \"everyone's\", 'suddenly', 'pray', 'await', 'threatened', 'extraordinarily', 'col', 'stems', 'tribe', 'personnel', 'gathered', 'aides', 'convinced', 'bloody', 'hostile', 'assisting', 'soul', 'privately', 'careful']\n",
      "\n",
      "\n",
      "Is it spam?:  1 \n",
      " false negative\n",
      "SPAM  4 :  ['x-status', 'coltd', 'x-keywords', 'leramilerctrorg']\n",
      "HAM  5 :  ['nights', 'stepped', 'buildings', 'sen', 'projection']\n",
      "\n",
      "\n",
      "Is it spam?:  0 \n",
      " false positive\n",
      "SPAM  2 :  ['jam', 'defective']\n",
      "HAM  2 :  ['zawodny', 'fond']\n",
      "\n",
      "\n",
      "Is it spam?:  0 \n",
      " false positive\n",
      "SPAM  2 :  ['qualifying', 'slovakia']\n",
      "HAM  2 :  ['guardian', 'recalled']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's do a deep dive into the errors and see if we can find words that could be\n",
    "# added to the intersection_set\n",
    "df_errors = df[(df['result']=='false positive') | (df['result']=='false negative')]\n",
    "for index, row in df_errors.iterrows():\n",
    "    li = list(row['words'].split(' '))\n",
    "    print('Is it spam?: ', row['spam'], \"\\n\", row['result'])\n",
    "    print(\"SPAM \", row['spamcount'], \": \", intersection(li, spamonly_set))\n",
    "    print(\"HAM \", row['hamcount'], \": \", intersection(li, hamonly_set))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the analysis above, we can create a set of words\n",
    "# we want to move from the spamonly_set into the intersection_set\n",
    "\n",
    "move_list = [] # put words in this list to be moved\n",
    "for each in move_list:\n",
    "    spamonly_set.remove(each)\n",
    "    intersection_set.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives:  101\n",
      "True negatives:  495\n",
      "False positives:  2\n",
      "False negatives:  7\n"
     ]
    }
   ],
   "source": [
    "# redoing the analysis with the updated word sets\n",
    "for ind in df.index:\n",
    "    li = list(df.loc[ind, 'words'].split(' '))\n",
    "    df.loc[ind, 'spamcount'] = len(intersection(li, spamonly_set))\n",
    "    df.loc[ind, 'hamcount'] = len(intersection(li, hamonly_set))\n",
    "    df.loc[ind, 'sharedcount'] = len(intersection(li, intersection_set))\n",
    "\n",
    "df['simple_prediction']=0 #default is that email is ham unless the condition is met\n",
    "df.loc[df['spamcount']>=df['hamcount'], 'simple_prediction']= 1\n",
    "df['result']='unknown'\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==1), 'result']= \"true positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==1), 'result']= \"false negative\"\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==0), 'result']= \"false positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==0), 'result']= \"true negative\"\n",
    "\n",
    "train = df[df['mask'] < 0.8]\n",
    "test = df[df['mask']>= 0.8]\n",
    "\n",
    "print(\"True positives: \", test[test['result'] == \"true positive\"].count()[\"result\"])\n",
    "print(\"True negatives: \", test[test['result'] == \"true negative\"].count()[\"result\"])\n",
    "print(\"False positives: \", test[test['result'] == \"false positive\"].count()[\"result\"])\n",
    "print(\"False negatives: \", test[test['result'] == \"false negative\"].count()[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
