{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the corpus and drop the missing rows\n",
    "df = pd.read_csv(\"./email_corpus.csv\")\n",
    "df = df.dropna()\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sample into 80% for training and 20% for testing\n",
    "df['mask'] = [np.random.uniform(0,1)  for k in df.index]\n",
    "train = df[df['mask'] < 0.8]\n",
    "test = df[df['mask']>= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two lists of words that bring together all of the words found\n",
    "# in the spam and ham training rows\n",
    "spamwords = []\n",
    "spamcount = 0\n",
    "hamwords = []\n",
    "hamcount = 0\n",
    "for index, row in train.iterrows():\n",
    "    li = list(row['words'].split(' '))\n",
    "    if row['spam']==1:\n",
    "        spamcount = spamcount + 1\n",
    "        spamwords = spamwords + li\n",
    "    else:\n",
    "        hamcount = hamcount + 1\n",
    "        hamwords = hamwords + li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamdist = nltk.FreqDist(hamwords)\n",
    "hamset = []\n",
    "for each in hamdist:\n",
    "    hamset.append(each)\n",
    "print(\"The number of words in all of the ham emails: \", len(hamset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamdist = nltk.FreqDist(spamwords)\n",
    "spamset = []\n",
    "for each in spamdist:\n",
    "    spamset.append(each)\n",
    "print(\"The number of words in all of the spam emails: \",len(spamset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "def difference (lst1, lst2):\n",
    "    result = []\n",
    "    for element in lst1:\n",
    "        if element not in lst2:\n",
    "            result.append(element)\n",
    "    return result\n",
    "    \n",
    "intersection_set = intersection(hamset, spamset)\n",
    "print(\"The number of words shared by ham and spam: \",len(intersection_set))\n",
    "\n",
    "spamonly_set = difference (spamset, hamset)\n",
    "print(\"The number of words only in spam: \", len(spamonly_set))\n",
    "\n",
    "hamonly_set = difference (hamset, spamset)\n",
    "print(\"The number of words only in ham: \", len(hamonly_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's go through the full dataframe now and get a count of ham, spam,\n",
    "# and shared words\n",
    "\n",
    "# create a column in the dataframe for spamcount\n",
    "df['spamcount']=0\n",
    "df['hamcount']=0\n",
    "df['sharedcount']=0\n",
    "\n",
    "for ind in df.index:\n",
    "    li = list(df.loc[ind, 'words'].split(' '))\n",
    "    df.loc[ind, 'spamcount'] = len(intersection(li, spamonly_set))\n",
    "    df.loc[ind, 'hamcount'] = len(intersection(li, hamonly_set))\n",
    "    df.loc[ind, 'sharedcount'] = len(intersection(li, intersection_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one approach we can take is to look at hamcount and spamcount\n",
    "# and just see which one is larger.  If spamcount>=hamcount,\n",
    "# then it seem logical that it is a spam email.  However,\n",
    "# when spamcount<hamcount, then it probably is ham.  Let's\n",
    "# try this on our testing data set.\n",
    "\n",
    "df['simple_prediction']=0 #default is that email is ham unless the condition is met\n",
    "df.loc[df['spamcount']>=df['hamcount'], 'simple_prediction']= 1\n",
    "df['result']='unknown'\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==1), 'result']= \"true positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==1), 'result']= \"false negative\"\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==0), 'result']= \"false positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==0), 'result']= \"true negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, we have a dataframe that is ready for analyzing\n",
    "\n",
    "train = df[df['mask'] < 0.8]\n",
    "test = df[df['mask']>= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's determine our confusion matrix\n",
    "print(\"True positives: \", test[test['result'] == \"true positive\"].count()[\"result\"])\n",
    "print(\"True negatives: \", test[test['result'] == \"true negative\"].count()[\"result\"])\n",
    "print(\"False positives: \", test[test['result'] == \"false positive\"].count()[\"result\"])\n",
    "print(\"False negatives: \", test[test['result'] == \"false negative\"].count()[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a deep dive into the errors and see if we can find words that could be\n",
    "# added to the intersection_set\n",
    "df_errors = df[(df['result']=='false positive') | (df['result']=='false negative')]\n",
    "for index, row in df_errors.iterrows():\n",
    "    li = list(row['words'].split(' '))\n",
    "    print('Is it spam?: ', row['spam'], \"\\n\", row['result'])\n",
    "    print(\"SPAM \", row['spamcount'], \": \", intersection(li, spamonly_set))\n",
    "    print(\"HAM \", row['hamcount'], \": \", intersection(li, hamonly_set))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_list = [] # put words in this list to be moved\n",
    "for each in move_list:\n",
    "    spamonly_set.remove(each)\n",
    "    intersection_set.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    li = list(df.loc[ind, 'words'].split(' '))\n",
    "    df.loc[ind, 'spamcount'] = len(intersection(li, spamonly_set))\n",
    "    df.loc[ind, 'hamcount'] = len(intersection(li, hamonly_set))\n",
    "    df.loc[ind, 'sharedcount'] = len(intersection(li, intersection_set))\n",
    "\n",
    "df['simple_prediction']=0 #default is that email is ham unless the condition is met\n",
    "df.loc[df['spamcount']>=df['hamcount'], 'simple_prediction']= 1\n",
    "df['result']='unknown'\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==1), 'result']= \"true positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==1), 'result']= \"false negative\"\n",
    "df.loc[(df['simple_prediction']==1) & (df['spam']==0), 'result']= \"false positive\"\n",
    "df.loc[(df['simple_prediction']==0) & (df['spam']==0), 'result']= \"true negative\"\n",
    "\n",
    "train = df[df['mask'] < 0.8]\n",
    "test = df[df['mask']>= 0.8]\n",
    "\n",
    "print(\"True positives: \", test[test['result'] == \"true positive\"].count()[\"result\"])\n",
    "print(\"True negatives: \", test[test['result'] == \"true negative\"].count()[\"result\"])\n",
    "print(\"False positives: \", test[test['result'] == \"false positive\"].count()[\"result\"])\n",
    "print(\"False negatives: \", test[test['result'] == \"false negative\"].count()[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
